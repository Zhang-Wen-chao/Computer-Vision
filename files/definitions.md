# 搞明白名词是什么意思，就理解了一大半了
## numpy
NumPy是Python語言的一個擴充程式庫。支援高階大規模的多維陣列與矩陣運算，此外也針對陣列運算提供大量的數學函數函式庫。NumPy的前身Numeric最早是由Jim Hugunin與其它協作者共同開發，2005年，Travis Oliphant在Numeric中結合了另一個同性質的程式庫Numarray的特色，並加入了其它擴充功能而開發了NumPy。NumPy為開放原始碼並且由許多協作者共同維護開發。
### cupy
CuPy 是一个使用 Python 编程语言进行 GPU 加速计算的开源库，提供对多维数组、稀疏矩阵以及在它们之上实现的各种数值算法的支持。 [3] CuPy 与 NumPy 和 SciPy 共享相同的 API 集，因此可以直接替代在 GPU 上运行 NumPy/SciPy 代码。 CuPy 从 v9.0 开始支持 NVIDIA CUDA GPU 平台和 AMD ROCm GPU 平台。[4][5]

CuPy 最初是作为 Chainer 深度学习框架的后端开发的，后来于 2017 年作为独立项目建立。 [6]

CuPy 是 NumPy 生态系统数组库的一部分 [7]，被广泛采用以通过 Python 使用 GPU，[8] 特别是在高性能计算环境中，例如 Summit、[9] Perlmutter、[10] EULER、[11] 和ABCI。[12]

CuPy 是 NumFOCUS 附属项目。[13]
## pytorch
PyTorch是一个用于构建深度学习模型的功能齐全的框架，这是一种机器学习类型，通常用于图像识别和语言处理等应用程序。用Python编写，对于大多数机器学习开发人员来说，它相对容易学习和使用。PyTorch的独特之处在于它对GPU的出色支持，以及它使用的反向模式自动微分，这使得计算图可以随时修改。这使得它成为快速实验和原型设计的热门选择。

动态图呢，就是直接对数据进行运算，然后动态的构建出运算图。很符合我们的运算习惯。

两者的区别在于，静态图先说明数据要怎么计算，然后再放入数据。假设要放入50组数据，运算图因为是事先构建的，所以每一次计算梯度都很快、高效；动态图的运算图是在数据计算的同时构建的，假设要放入50组数据，那么就要生成50次运算图。这样就没有那么高效。所以称为动态图。

动态图虽然没有那么高效，但是他的优点有以下：

更容易调试。
动态计算更适用于自然语言处理。（这个可能是因为自然语言处理的输入往往不定长？）
动态图更面向对象编程，我们会感觉更加自然。
### profiler
PyTorch 包含一个剖析器 API，用于识别代码中各种 PyTorch 操作的时间和内存成本。
代码中各种 PyTorch 操作的时间和内存成本。剖析器可以
可以很容易地集成到代码中，其结果可以打印成表格
或在 JSON 跟踪文件中返回。
###　torchtext
torchtext 包由数据处理实用程序和流行的自然语言数据集组成。
### TorchScript
TorchScript 是一种从 PyTorch 代码创建可序列化和可优化模型的方法。 任何 TorchScript 程序都可以从 Python 进程保存并加载到不存在 Python 依赖项的进程中。

PyTorch 能极大地提高想 idea、做实验、发论文的效率，是训练框架中的豪杰，但是它不适合部署。动态建图带来的优势对于性能要求更高的应用场景而言更像是缺点，非固定的网络结构给网络结构分析并进行优化带来了困难，多数参数都能以 Tensor 形式传输也让资源分配变成一件闹心的事。另外由于图是由 python 代码构建的，一方面部署要依赖 python 环境，另一方面模型也毫无保密性可言。

而 TorchScript 就是为了解决这个问题而诞生的工具。包括代码的追踪及解析、中间表示的生成、模型优化、序列化等各种功能，可以说是覆盖了模型部署的方方面面。今天我们先简要地介绍一些 TorchScript 的功能，让大家有一个初步的认识，进阶的解读会陆续推出～


TorchScript 解读（一）：初识 TorchScript - OpenMMLab的文章 - 知乎
https://zhuanlan.zhihu.com/p/486914187

### Tensorflow
静态图则意味着计算图的构建和实际计算是分开（define and run）的。在静态图中，会事先了解和定义好整个运算流，这样之后再次运行的时候就不再需要重新构建计算图了（可理解为编译），因此速度会比动态图更快，从性能上来说更加高效，但这也意味着你所期望的程序与编译器实际执行之间存在着更多的代沟，代码中的错误将难以发现，无法像动态图一样随时拿到中间计算结果。Tensorflow默认使用的是静态图机制，这也是其名称的由来，先定义好整个计算流（flow），然后再对数据（tensor）进行计算。
## Knowledge Distillation 
知识提炼是一种技术，可将知识从计算成本高昂的大型模型转移到较小的模型，而不会失去有效性。这样就可以在功能较弱的硬件上进行部署，使评估更快、更高效。

## cuda
CUDA（Compute Unified Device Architecture，統一計算架構[1]）是由輝達NVIDIA所推出的一種軟硬體整合技術，是該公司對於GPGPU的正式名稱。透過這個技術，使用者可利用NVIDIA的GPU進行圖像處理之外的運算，亦是首次可以利用GPU作為C-編譯器的開發環境。CUDA 開發套件（CUDA Toolkit ）只能將自家的CUDA C-語言（對OpenCL只有連結的功能[2]），也就是執行於GPU的部分編譯成PTX中間語言或是特定NVIDIA GPU架構的機器碼（NVIDIA 官方稱為 "device code"）；而執行於中央處理器部分的C / C++程式碼（NVIDIA 官方稱為 "host code"）仍依賴於外部的編譯器，如Microsoft Windows下需要Microsoft Visual Studio；Linux下則主要依賴於GCC。
### cudnn
CUDA Deep Neural Network

NVIDIA CUDA® 深度神经网络库 (cuDNN) 是一个 GPU 加速的深度神经网络基元库，能够以高度优化的方式实现标准例程（如前向和反向卷积、池化层、归一化和激活层）。

全球的深度学习研究人员和框架开发者都依赖 cuDNN 来实现高性能 GPU 加速。借助 cuDNN，研究人员和开发者可以专注于训练神经网络及开发软件应用，而不必花时间进行低层级的 GPU 性能调整。cuDNN 可加速广泛应用的深度学习框架，包括 Caffe2、Chainer、Keras、MATLAB、MxNet、PaddlePaddle、PyTorch 和 TensorFlow。如需获取经 NVIDIA 优化且已在框架中集成 cuDNN 的深度学习框架容器，请访问 NVIDIA GPU CLOUD 了解详情并开始使用。
## conda
Conda 是一个开源包管理系统和环境管理系统，可在 Windows、macOS 和 Linux 上运行。 Conda 可以快速安装、运行和更新软件包及其依赖项。 Conda 可以轻松地在本地计算机上创建、保存、加载环境并在环境之间切换。 它是为 Python 程序创建的，但它可以打包和分发任何语言的软件。
## pip
pip is the package installer for Python. You can use pip to install packages from the Python Package Index and other indexes.

## cnn 
卷积神经网络（英語：Convolutional Neural Network，縮寫：CNN）是一种前馈神经网络，它的人工神经元可以响应一部分覆盖范围内的周围单元，[1]对于大型图像处理有出色表现。

卷积神经网络由一个或多个卷积层和顶端的全连通层（对应经典的神经网络）组成，同时也包括关联权重和池化层（pooling layer）。这一结构使得卷积神经网络能够利用输入数据的二维结构。与其他深度学习结构相比，卷积神经网络在图像和语音识别方面能够给出更好的结果。这一模型也可以使用反向传播算法进行训练。相比较其他深度、前馈神经网络，卷积神经网络需要考量的参数更少，使之成为一种颇具吸引力的深度学习结构[2]。

卷积神经网络的灵感来自于动物视觉皮层组织的神经连接方式。单个神经元只对有限区域内的刺激作出反应，不同神经元的感知区域相互重叠从而覆盖整个视野。
### batch size设置技巧
https://cloud.tencent.com/developer/article/2197061

怎么选取训练神经网络时的Batch size? - Summer Clover的回答 - 知乎
https://www.zhihu.com/question/61607442/answer/1875700191
## gan
生成对抗网络（英語：Generative Adversarial Network，简称GAN）是非监督式学习的一种方法，透過两个神经網路相互博弈的方式进行学习。该方法由伊恩·古德费洛等人于2014年提出。[1] 生成對抗網絡由一個生成網絡與一個判別網絡組成。生成網絡從潛在空間（latent space）中隨機取樣作為輸入，其輸出結果需要盡量模仿訓練集中的真實樣本。判別網絡的輸入則為真實樣本或生成網絡的輸出，其目的是將生成網絡的輸出從真實樣本中盡可能分辨出來。而生成網絡則要盡可能地欺騙判別網絡。兩個網絡相互對抗、不斷調整參數，最終目的是使判別網絡無法判斷生成網絡的輸出結果是否真實。
生成對抗網絡常用於生成以假亂真的圖片。[4]此外，該方法還被用於生成影片[5]、三維物體模型[6]等。

生成對抗網絡虽然最开始提出是為了無監督學習，但经證明對半監督學習[4]、完全監督學習[7] 、強化學習[8]也有效。 在2016年的一個研討會上，杨立昆称生成式對抗網絡为「機器學習這二十年來最酷的想法」[9]。
### dcgan
Deep Convolutional GAN

DCGAN，即深度卷积 GAN，是一种生成对抗网络架构。 它使用了一些准则，特别是：

用跨步卷积（鉴别器）和分数跨步卷积（生成器）替换任何池化层。
在生成器和鉴别器中使用批归一化。
删除完全连接的隐藏层以获得更深的架构。
在生成器中对除输出之外的所有层使用 ReLU 激活，输出使用 tanh。
在所有层的判别器中使用 LeakyReLU 激活。
## Transfer learning
迁移学习 是属于机器学习的一种研究领域。它专注于存储已有问题的解决模型，并将其利用在其他不同但相关问题上。[1] 比如说，用来辨识汽车的知识（或者是模型）也可以被用来提升识别卡车的能力。计算机领域的迁移学习和心理学常常提到的学习迁移在概念上有一定关系，但是两个领域在学术上的关系非常有限。
### 迁移学习与fine-tuning有什么区别？
举个例子，假设今天老板给你一个新的数据集，让你做一下图片分类，这个数据集是关于Flowers的。问题是，数据集中flower的类别很少，数据集中的数据也不多，你发现从零训练开始训练CNN的效果很差，很容易过拟合。怎么办呢，于是你想到了使用Transfer Learning，用别人已经训练好的Imagenet的模型来做。

做的方法有很多：
把Alexnet里卷积层最后一层输出的特征拿出来，然后直接用SVM分类。这是Transfer Learning，因为你用到了Alexnet中已经学到了的“知识”。

把Vggnet卷积层最后的输出拿出来，用贝叶斯分类器分类。思想基本同上。

甚至你可以把Alexnet、Vggnet的输出拿出来进行组合，自己设计一个分类器分类。这个过程中你不仅用了Alexnet的“知识”，也用了Vggnet的“知识”。

最后，你也可以直接使用fine-tune这种方法，在Alexnet的基础上，重新加上全连接层，再去训练网络。

综上，Transfer Learning关心的问题是：什么是“知识”以及如何更好地运用之前得到的“知识”。这可以有很多方法和手段。而fine-tune只是其中的一种手段。
## Sequence Models
序列模型是输入或输出数据序列的机器学习模型。序列数据包括文本流、音频片段、视频片段、时间序列数据等。递归神经网络是序列模型中常用的算法。
### Recurrent Neural Network (RNN)
循环神经网络（Recurrent neural network：RNN）是神經網絡的一種。单纯的RNN因为无法处理随着递归，权重指数级爆炸或梯度消失问题，难以捕捉长期时间关联；而结合不同的LSTM可以很好解决这个问题。[1][2]

时间循环神经网络可以描述动态时间行为，因为和前馈神经网络（feedforward neural network）接受较特定结构的输入不同，RNN将状态在自身网络中循环传递，因此可以接受更广泛的时间序列结构输入。手写识别是最早成功利用RNN的研究结果。
### Long Short Term Memory (LSTM)
长短期记忆（英語：Long Short-Term Memory，LSTM）是一种时间循环神经网络（RNN）[1]，论文首次发表于1997年。由于独特的设计结构，LSTM适合于处理和预测时间序列中间隔和延迟非常长的重要事件。

LSTM的表现通常比时间循环神经网络及隐马尔科夫模型（HMM）更好，比如用在不分段连续手写识别上[2]。2009年，用LSTM构建的人工神经网络模型赢得过ICDAR手写识别比赛冠军。LSTM还普遍用于自主语音识别，2013年運用TIMIT自然演講資料庫達成17.7%錯誤率的紀錄。作为非线性模型，LSTM可作为复杂的非线性单元用于构造更大型深度神经网络。

通常情况，一个LSTM单元由细胞单元（cell）、输入门（input gate）、输出门（output gate）[3]、遗忘门（forget gate）[4]组成。
## Transformers
Transformer模型（直译为“变换器”）是一种采用自注意力机制的深度学习模型，这一机制可以按输入数据各部分重要性的不同而分配不同的权重。该模型主要用于自然语言处理（NLP）与计算机视觉（CV）领域。[1]

与循环神经网络（RNN）一样，Transformer模型旨在处理自然语言等顺序输入数据，可应用于翻译、文本摘要等任务。而与RNN不同的是，Transformer模型能够一次性处理所有输入数据。注意力机制可以为输入序列中的任意位置提供上下文。如果输入数据是自然语言，则Transformer不必像RNN一样一次只处理一个单词，这种架构允许更多的并行计算，并以此减少训练时间。[2]

Transformer模型于2017年由谷歌大脑的一个团队推出[2]，现已逐步取代长短期记忆（LSTM）等RNN模型成为了NLP问题的首选模型。[3]并行化优势允许其在更大的数据集上进行训练。这也促成了BERT、GPT等预训练模型的发展。这些系统使用了维基百科、Common Crawl等大型语料库进行训练，并可以针对特定任务进行微调。
### T5 Model
the Text-To-Text Transfer Transformer - transformers API
T5 通过为每个任务对应的输入添加不同的前缀，可以很好地直接应用在各种任务上(开盒即食)，例如(图中左上角红色箭头标出):
### Vision Transformer
Transformer 在自然语言处理 (NLP) 任务中找到了最初的应用，如 BERT 和 GPT-3 等语言模型所证明的那样。 相比之下，典型的图像处理系统使用卷积神经网络（CNN）。 知名项目包括 Xception、ResNet、EfficientNet、[2] DenseNet、[3] 和 Inception。[1]

Transformer 测量输入标记对（文本字符串中的单词）之间的关系，称为注意力。 成本是代币数量的二次方。 对于图像来说，分析的基本单位是像素。 然而，计算典型图像中每个像素对的关系在内存和计算方面是令人望而却步的。 相反，ViT 计算图像各个小部分（例如 16x16 像素）中像素之间的关系，从而大大降低了成本。 这些部分（具有位置嵌入）按顺序放置。 嵌入是可学习的向量。 每个部分被排列成线性序列并乘以嵌入矩阵。 带有位置嵌入的结果被馈送到变压器。[1]

与 BERT 的情况一样，分类任务中的基本作用是由类别标记发挥的。 一种特殊令牌，用作最终 MLP Head 的唯一输入，因为它受到所有其他令牌的影响。

图像分类的架构是最常见的，仅使用 Transformer Encoder 来转换各种输入标记。 然而，还有其他应用也使用传统 Transformer 架构的解码器部分。
### DeiT
ViT 文中表示数据量不足会导致 ViT 效果变差。针对以上问题，DeiT 核心共享是使用了蒸馏策略，能够仅使用 ImageNet-1K 数据集就就可以达到 83.1% 的 Top1。

那么文章主要贡献可以总结为三点：

仅使用 Transformer，不引入 Conv 的情况下也能达到 SOTA 效果。
提出了基于 token 蒸馏的策略，针对 Transformer 蒸馏方法超越传统蒸馏方法。
DeiT 发现使用 Convnet 作为教师网络能够比使用 Transformer 架构效果更好。
## Natural language processing
自然語言處理（英語：Natural Language Processing，缩写作 NLP）是人工智慧和語言學領域的分支學科。此領域探討如何處理及運用自然語言；自然語言處理包括多方面和步骤，基本有认知、理解、生成等部分。

自然語言認知和理解是讓電腦把输入的語言变成有意思的符号和关系，然后根据目的再處理。自然語言生成系統则是把計算機數據轉化為自然語言。
### Word embedding
词嵌入（Word embedding）是自然语言处理（NLP）中语言模型与表征学习技术的统称。概念上而言，它是指把一个维数为所有词的数量的高维空间嵌入到一个维数低得多的连续向量空间中，每个单词或词组被映射为实数域上的向量。

词嵌入的方法包括人工神经网络[1]、对词语同现矩阵降维[2][3][4]、機率模型[5]以及单词所在上下文的显式表示等。[6]

在底层输入中，使用词嵌入来表示词组的方法极大提升了NLP中语法分析器[7]和文本情感分析等的效果。
## chatbot
聊天機器人（ChatBot）是由對話或文字進行交談的電腦程式[1]，能夠模擬人類對話並通過圖靈測試，也可具備實用性，如客戶服務或資訊獲取。

有些聊天機器人會搭載自然語言處理系統，但大多簡單的系統只會擷取輸入的關鍵字，再從語料庫中找尋最合適的應答句。目前，聊天機器人是虛擬助理的一部分，可以與許多組織的應用程式、網站和通訊平台連接[2][3]。非助理應用程式包括娛樂目的的聊天室，研究和特定產品促銷，社交機器人等。

## FGSM：Fast Gradient Sign Method
在图像攻击算法中，FGSM（fast gradient sign method）是非常经典的一个算法。这篇发表于ICLR2015的文章通过梯度来生成攻击噪声，核心思想就是Figure1所示的内容。Figure1中左边图是常规的图像，一般的分类模型都会将其分类为熊猫（panda），但是通过添加由网络梯度生成的攻击噪声后，得到右边的攻击图像，虽然看起来还是熊猫，但是模型却将其分类为长臂猿（gibbon）。
## Multimodal AI
多模态AI是一种新的人工智能范式，因此也被称为“多模态人工智能”，它将各种数据类型与多种智能处理算法相结合，以实现更高的性能。