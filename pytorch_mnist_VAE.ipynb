{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5owukkX6rIc"
   },
   "source": [
    "# Pytorch Tutorial 2: VAE (Variational AutoEncoder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Vaklu0o6cfE"
   },
   "outputs": [],
   "source": [
    "# prerequisites\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Current device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FUEdmpg8gA8-"
   },
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oO_PtxqJ6cfG"
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, h1_dim, h2_dim, z_dim):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        # encoder part\n",
    "        self.fc1 = nn.Linear(x_dim, h1_dim)\n",
    "        self.fc2 = nn.Linear(h1_dim, h2_dim)\n",
    "        self.fc31 = nn.Linear(h2_dim, z_dim)\n",
    "        self.fc32 = nn.Linear(h2_dim, z_dim)\n",
    "        # decoder part\n",
    "        self.fc4 = nn.Linear(z_dim, h2_dim)\n",
    "        self.fc5 = nn.Linear(h2_dim, h1_dim)\n",
    "        self.fc6 = nn.Linear(h1_dim, x_dim)\n",
    "\n",
    "    def encoder(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        return self.fc31(x), self.fc32(x) # mu, log_var\n",
    "\n",
    "    def sampling(self, mu, log_var):\n",
    "        \"\"\"\n",
    "            Note:\n",
    "                z = mu + var * noise\n",
    "\n",
    "            Args:\n",
    "                mu (torch.Tensor):\n",
    "                    mean of the sampled noise.\n",
    "                log_var (torch.Tensor):\n",
    "                    Logarithmic result of variance of the sampled noise.\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        sampled_z = eps * std\n",
    "\n",
    "        return sampled_z.add_(mu) # return z sample\n",
    "\n",
    "    def decoder(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        h = F.relu(self.fc5(h))\n",
    "\n",
    "        return F.sigmoid(self.fc6(h))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encoder(x.view(-1, 784))\n",
    "        z = self.sampling(mu, log_var)\n",
    "\n",
    "        return self.decoder(z), mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k2dVYgD0kzb2"
   },
   "outputs": [],
   "source": [
    "# build model\n",
    "vae = VAE(x_dim=784, h1_dim= 512, h2_dim=256, z_dim=2)\n",
    "vae = vae.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9wDUaWafaRP"
   },
   "source": [
    "## Loss Function\n",
    "\n",
    "### You can try to learn more about the design of loss function applied in VAE. We do not introduce this part for you in our tutorial. But we could provide some keywords to help you search related info.\n",
    "\n",
    "**Keywords**: latent variable model, ELBO, reparameterization, KL divergence,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eaHcg-LT6cfH"
   },
   "outputs": [],
   "source": [
    "# return reconstruction error + KL divergence losses\n",
    "def loss_fn(recon_x, x, mu, log_var):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DhSXiA5Mkoez"
   },
   "source": [
    "## Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "lr = 1e-3\n",
    "all_epoch = 5  # reduce the number of epochs if your do not have a powerful GPU\n",
    "batch_size = 100\n",
    "\n",
    "# MNIST Dataset\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='./mnist_data/',\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./mnist_data/',\n",
    "    train=False,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=False\n",
    ")\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f'training set: {len(train_dataset)}')\n",
    "print(f'test set: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHfqAnsklCyI"
   },
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_ztyZthlFYY"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(vae.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-lYWnTEpO8U"
   },
   "source": [
    "## Train & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "for current_epoch in range(all_epoch):\n",
    "    # training\n",
    "    vae.train()\n",
    "\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        # forward pass\n",
    "        recon_batch, mu, log_var = vae(data)\n",
    "        # compute loss of the current batch\n",
    "        loss = loss_fn(recon_batch, data, mu, log_var)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\n",
    "                f'Epoch {current_epoch+1}, '\n",
    "                f'[{batch_idx * len(data)}/{len(train_loader.dataset)}'\n",
    "                f' ({100. * batch_idx / len(train_loader):.0f})]\\t'\n",
    "                f'Loss: {loss.item() / len(data):.4f}'\n",
    "            )\n",
    "            losses.append(loss.item() / len(data))\n",
    "\n",
    "    # evaluation\n",
    "    vae.eval()\n",
    "    test_loss= 0\n",
    "    with torch.no_grad():  # Note: `torch.no_grad()`\n",
    "        for data, _ in test_loader:\n",
    "            data = data.to(device)\n",
    "            recon, mu, log_var = vae(data)\n",
    "            loss = loss_fn(recon, data, mu, log_var)\n",
    "\n",
    "            # sum up batch loss\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print(f'Test set loss: {test_loss:.4f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "# we record some loss values except for the first one\n",
    "# because its value is too enormous\n",
    "plt.plot(losses[1:])\n",
    "plt.xlabel(\"Checkpoints\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training loss curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dMUJhAtshne"
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # in the generation process,\n",
    "    # we only use the decoder of VAE,\n",
    "    # and the input is a Gaussian noise\n",
    "    z = torch.randn(64, 2).to(device)\n",
    "    sample = vae.decoder(z).to(device)\n",
    "    sample = sample.reshape(64, 1, 28, 28).cpu().numpy()\n",
    "    sample = sample.transpose(0, 2, 3, 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.axis('off') # 关掉坐标轴为 off\n",
    "plt.title('Example')\n",
    "# we have 64 generated images, and only visualize the first one\n",
    "plt.imshow(sample[0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
